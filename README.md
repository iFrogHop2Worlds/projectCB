# projectCB

**Is a webcrawling data engine. Which enables a host of applications and services.** 

The current frontend is a prototype of an application which will consume data provided from the crawler engine.
later we will have crawler user dashboard as well as other aplpications proccessing, serving and consuming data.

To start working with teh code simply

(1) setup your mongo database instance.
<br>
db name = MetaDeck
<br>
  collection names = [
<ul>
   <li><ColelctionName>These values are marked to change. if this is not updated message me.</li>
   <li><ColelctionName></li>
   <li><ColelctionName></li>
   <li><ColelctionName></li>
   <li><ColelctionName></li>
   <li><ColelctionName></li>
</ul>
]

(2) set your .env value to match your database 

(3) npm/yarn install (backend folder and frontend if you want to play with that)

(4) npm start (backend for server/crawler && frontend if you want that)
                


